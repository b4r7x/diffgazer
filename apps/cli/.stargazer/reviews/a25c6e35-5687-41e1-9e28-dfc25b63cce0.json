{
  "metadata": {
    "id": "a25c6e35-5687-41e1-9e28-dfc25b63cce0",
    "projectPath": "/Users/voitz/Projects/stargazer/apps/cli",
    "createdAt": "2026-01-22T18:51:26.590Z",
    "staged": false,
    "branch": "feature/review-bounding",
    "overallScore": null,
    "issueCount": 0,
    "criticalCount": 0,
    "warningCount": 0,
    "sessionId": null
  },
  "result": {
    "summary": "{\n  \"summary\": \"This diff introduces a new 'Chat' feature, enhances the 'Review' feature with chunked processing and improved display, and refactors 'Settings' to allow editing AI model parameters like `maxTokens`. It also includes critical security fixes for Unicode handling and improved prompt injection defenses, alongside a significant refactoring of storage integration tests. The changes are largely positive, but some areas could be improved for robustness and clarity.\",\n  \"issues\": [\n    {\n      \"severity\": \"critical\",\n      \"category\": \"security\",\n      \"file\": \"apps/server/src/services/review.ts\",\n      \"line\": 39,\n      \"title\": \"Prompt Injection Vulnerability - Regression in Diff Escaping\",\n      \"description\": \"The change in `CODE_REVIEW_PROMPT` from XML-tagged and escaped diff content (`<code-diff>{diff}</code-diff>` with `escapeXml`) to a markdown fenced block (````diff\\\\n{diff}\\\\n````) represents a significant regression in prompt injection defense. Markdown fences are not a robust security boundary against an attacker who can control the diff content. An attacker could potentially close the markdown fence within the diff and inject new instructions to the AI. The previous XML escaping was a stronger, explicit technical control.\",\n      \"suggestion\": \"Revert to using XML tags for enclosing the diff content and ensure proper XML entity escaping (`escapeXml`) is applied to the diff string. This provides a more robust technical control against arbitrary instruction injection. Relying solely on the AI to 'ignore embedded prompts' is less secure than a technical barrier.\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"category\": \"reliability\",\n      \"file\": \"apps/server/src/api/routes/review.ts\",\n      \"line\": 105,\n      \"title\": \"Silent Failure to Save Review or Link Session\",\n      \"description\": \"The `onComplete` callbacks for both `/review/stream` and `/review/stream/chunked` contain `try...catch` blocks that explicitly ignore errors during `saveReview` and `addReviewToSession`. While the comment 'Ignore save errors - review was already streamed' explains the intent (not blocking the stream), silently failing to save or link means the review history or session state could become inconsistent. The user or operator will not be aware of these data integrity issues.\",\n      \"suggestion\": \"Implement server-side logging for errors that occur during `saveReview` and `addReviewToSession`. This ensures that even if the client doesn't receive an explicit error (because the review was streamed), the server logs the data integrity problem for monitoring and debugging.\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"category\": \"reliability\",\n      \"file\": \"apps/cli/src/app/app.tsx\",\n      \"line\": 64,\n      \"title\": \"Silent Error in `handleDiscussReview` PATCH request\",\n      \"description\": \"The `handleDiscussReview` function includes a `try...catch` block around the `api().request('PATCH', ...)` call to link a review to a session. This catch block explicitly comments `// Ignore errors - continue anyway`. This means if the API call to link the review fails, the user will not receive any feedback, and the client-side state might incorrectly assume the review is linked, leading to an inconsistent user experience.\",\n      \"suggestion\": \"Implement client-side error feedback, such as an `ink` toast notification or a console error log, if the `PATCH` request to link the review to the session fails. This provides transparency to the user and aids debugging.\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"category\": \"performance\",\n      \"file\": \"packages/core/src/ai/providers/gemini.ts\",\n      \"line\": 15,\n      \"title\": \"Overly Generous Default Max Output Tokens for Gemini\",\n      \"description\": \"The `DEFAULT_MAX_OUTPUT_TOKENS` for Gemini is set to `65536`. While Gemini 1.5 Flash supports large contexts, a default output limit this high can lead to significantly increased token usage, longer generation times, and higher costs, even if the AI doesn't always fill the entire context. It's generally safer to have a more conservative default output token limit.\",\n      \"suggestion\": \"Reconsider the `DEFAULT_MAX_OUTPUT_TOKENS` for Gemini. A more conservative default (e.g., 4096 or 8192 tokens) would be prudent, allowing users to explicitly increase this limit via the new settings screen if their use case requires very verbose AI responses.\"\n    },\n    {\n      \"severity\": \"suggestion\",\n      \"category\": \"maintainability\",\n      \"file\": \"apps/server/src/api/routes/review.ts\",\n      \"line\": 13,\n      \"title\": \"Utility Functions Placed Directly in Route File\",\n      \"description\": \"The `extractJson`, `VALID_SEVERITIES`, `SEVERITY_MAP`, `VALID_CATEGORIES`, `CATEGORY_MAP`, and `normalizeReviewResponse` utilities are defined directly within the `review.ts` route file. While functional, `extractJson` is a generic parsing utility and the normalization logic could be considered a service layer concern or a dedicated utility module for AI response processing. Placing them directly in the route file can make it less focused on routing and harder to reuse.\",\n      \"suggestion\": \"Consider moving `extractJson` to a shared utility module (e.g., `packages/core/src/utils/json.ts`). The normalization logic (`normalizeReviewResponse` and its related maps) could be moved to a `review-utils.ts` or similar file within `apps/server/src/services` to improve separation of concerns and maintainability.\"\n    },\n    {\n      \"severity\": \"suggestion\",\n      \"category\": \"performance\",\n      \"file\": \"apps/server/src/services/review.ts\",\n      \"line\": 5,\n      \"title\": \"Increased `MAX_DIFF_SIZE_BYTES` for Non-Chunked Review\",\n      \"description\": \"The `MAX_DIFF_SIZE_BYTES` for the non-chunked review endpoint has been increased from 100KB to 500KB. While the new chunked review feature addresses very large total diffs, a single diff file of 500KB can still be very large for a single AI prompt. This could lead to higher token consumption, longer processing times, and increased costs for the AI provider if not carefully managed by the `maxTokens` setting.\",\n      \"suggestion\": \"While the `maxTokens` setting provides some control, consider if 500KB is the optimal limit for a *single* diff in the non-chunked path. A slightly more conservative limit for the non-chunked path, or emphasizing the use of the chunked endpoint for larger changes, might be beneficial. Document the implications of this limit for users.\"\n    },\n    {\n      \"severity\": \"nitpick\",\n      \"category\": \"logic\",\n      \"file\": \"apps/cli/src/app/app.tsx\",\n      \"line\": 169,\n      \"title\": \"Ambiguous `chat.reset()` behavior on exit\",\n      \"description\": \"When exiting the chat view by pressing ESC or 'b', `chat.reset()` is called. This clears the chat state. Depending on the desired user experience, it might be preferable to preserve the chat history if the user navigates away and then returns to the *same* session. If `chat.reset()` clears the entire session's messages, it could be jarring for the user.\",\n      \"suggestion\": \"Clarify the intended behavior of `chat.reset()` when navigating away from the chat view. If the goal is to allow users to return to an ongoing conversation, `chat.reset()` should either be more granular (e.g., only clearing temporary input) or not called on simple navigation away, only when explicitly starting a new chat or session.\"\n    },\n    {\n      \"severity\": \"nitpick\",\n      \"category\": \"schema\",\n      \"file\": \"packages/schemas/src/review.ts\",\n      \"line\": 42,\n      \"title\": \"Optional `reviewId` in `complete` stream event\",\n      \"description\": \"The `reviewId` field in the `complete` stream event is defined as `nullable().optional()`. If `reviewId` is always intended to be present (even if `null` when saving fails), then `optional()` might be redundant or misleading. `nullable()` alone would indicate it could be `null` but would always be part of the JSON structure. `optional()` implies it might not be present at all.\",\n      \"suggestion\": \"If `reviewId` is expected to always be provided in the `complete` event (as `string` or `null`), remove `.optional()` from its schema definition. If there are scenarios where the `reviewId` key itself might be entirely absent from the JSON, then `optional()` is correct. Clarify the exact intent for this field's presence.\"\n    },\n    {\n      \"severity\": \"nitpick\",\n      \"category\": \"style\",\n      \"file\": \"apps/server/src/api/routes/config.ts\",\n      \"line\": 52,\n      \"title\": \"Complex `maxTokens` update logic\",\n      \"description\": \"The logic for updating `maxTokens` in the `PATCH /config` endpoint: `maxTokens: body.maxTokens === null ? undefined : (body.maxTokens ?? existing.value.maxTokens)` is functional but a bit dense. It correctly handles `null` to reset to default (`undefined`), and provided values, but can be hard to parse quickly.\",\n      \"suggestion\": \"Refactor the logic for updating `maxTokens` to be more explicit, for example using an `if/else if` chain, to improve readability and make the intent clearer for future maintainers. Example: `let newMaxTokens = existing.value.maxTokens; if (body.maxTokens === null) { newMaxTokens = undefined; } else if (body.maxTokens !== undefined) { newMaxTokens = body.maxTokens; }`\"\n    }\n  ],\n  \"overallScore\": 8\n}",
    "issues": []
  },
  "gitContext": {
    "branch": "feature/review-bounding",
    "fileCount": 33
  }
}
